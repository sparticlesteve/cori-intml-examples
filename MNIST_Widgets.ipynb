{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup an IPyParallel cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcluster_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"isc_ihpc_mnist\"\n",
    "nodes = 8\n",
    "module = \"python/3.6-anaconda-4.4\"\n",
    "conda_env = \"/global/cscratch1/sd/sfarrell/conda/isc-ihpc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%ipcluster -m $module -e $conda_env -N $nodes -J $job_name -t 1:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect a client to the running IPP cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to IPP controller\n",
    "import time\n",
    "import ipyparallel as ipp\n",
    "\n",
    "c = None\n",
    "wait_time = 5\n",
    "retries = 3\n",
    "while retries > 0:\n",
    "    print(\"checking ipcontroller...\")\n",
    "    try:\n",
    "        c = ipp.Client()\n",
    "        print(\"ipcontroller is running\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e.args)\n",
    "        print(\"ipcontroller is not running yet, waiting {} seconds before retry...\".format(wait_time))\n",
    "        time.sleep(wait_time)\n",
    "        retries -= 1\n",
    "\n",
    "wait_time = 10\n",
    "retries = 3\n",
    "while c is not None and retries > 0:\n",
    "    if len(c.ids) == 0:\n",
    "        print(\"engines are not registered yet with controller, waiting {} seconds before retry...\".format(wait_time))\n",
    "        time.sleep(wait_time)\n",
    "        retries -= 1\n",
    "    elif len(c.ids) < nodes:\n",
    "        print(\"not all engines have registered, waiting {} seconds...\".format(wait_time))\n",
    "        time.sleep(wait_time)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "if c is not None:\n",
    "    lv = c.load_balanced_view()\n",
    "    dv = c.direct_view()\n",
    "    print(c.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactively run multiple parameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "x_train, y_train, x_test, y_test = mnist.load_data()\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "# Hold these parameters constant\n",
    "import os\n",
    "\n",
    "checkpoint_dir = '/global/cscratch1/sd/$USER/cori-interactive-dl/mnist-hpo'\n",
    "n_samples = 1000\n",
    "\n",
    "fixed_params = {\n",
    "    \"verbose\": 0,\n",
    "    \"batch_size\": 128,\n",
    "    \"nthreads\": 8,\n",
    "    \"n_epochs\": 32,\n",
    "    \"valid_frac\": 0.17,\n",
    "#    \"checkpoint_file\": os.path.join(os.path.expandvars(checkpoint_dir), 'model_single.h5'),\n",
    "    \"x_train\": x_train[:n_samples], \n",
    "    \"y_train\": y_train[:n_samples]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_hpo_trials = 8\n",
    "grid_h1 = np.random.choice([4, 8, 16, 32, 64], size=n_hpo_trials)\n",
    "grid_h2 = np.random.choice([4, 8, 16, 32, 64], size=n_hpo_trials)\n",
    "grid_h3 = np.random.choice([8, 16, 32, 64, 128], size=n_hpo_trials)\n",
    "grid_dropout = np.random.rand(n_hpo_trials)\n",
    "grid_optimizer = np.random.choice(['Adadelta', 'Adam', 'Nadam'], size=n_hpo_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "from mlextras import build_and_train\n",
    "from hpo_widgets import ModelPlot, ParamSpanWidget\n",
    "\n",
    "run_training = ft.partial(build_and_train, **fixed_params)\n",
    "plot_metrics = ft.partial(\n",
    "    ModelPlot,\n",
    "    y=['loss', 'acc', 'val_loss', 'val_acc'],\n",
    "    xlim=[0, fixed_params[\"n_epochs\"]],\n",
    "    xlabel='epochs',\n",
    "    ylabel='training metrics'\n",
    ")\n",
    "\n",
    "hpo_params = dict(\n",
    "    h1=grid_h1,\n",
    "    h2=grid_h2,\n",
    "    h3=grid_h3,\n",
    "    dropout=grid_dropout,\n",
    "    optimizer=grid_optimizer\n",
    ")\n",
    "\n",
    "psw = ParamSpanWidget(\n",
    "    run_training, \n",
    "    plot_metrics, \n",
    "    hpo_params)\n",
    "\n",
    "psw.submit_computations()\n",
    "\n",
    "psw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psw.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for m in psw.model_plots:\n",
    "    display(m.debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at additional model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "for i in range(len(psw.model_runs)):\n",
    "    pprint.pprint(psw.model_runs[i].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release job resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab the job id for connecting to this cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{job_name}\" --out job_id\n",
    "#capture the jobid to a variable\n",
    "squeue -u $USER -n $1 | awk '{if (NR!=1) {printf \"%s\", $1}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancel the current job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{job_id}\"\n",
    "scancel $1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isc-ihpc",
   "language": "python",
   "name": "isc-ihpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
